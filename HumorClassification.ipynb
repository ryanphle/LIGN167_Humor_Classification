{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "Build the RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(list)\n",
    "with open(\"../review.json\", \"r\") as file:\n",
    "    for line in file:\n",
    "        d = json.loads(line)\n",
    "        data[d['funny'] > 0].append((d['review_id'], d['text'], d['funny'] > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the data\n",
    "sentences = random.sample(data[True], num_samples)\n",
    "sentences.extend(random.sample(data[False], num_samples))\n",
    "random.shuffle(sentences)\n",
    "\n",
    "del data[True]\n",
    "del data[False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the sentences\n",
    "def parseSentenceBasic(sentence):\n",
    "    sent = sentence[1].strip().split()\n",
    "    return [x.lower() for x in sent]\n",
    "\n",
    "def parseSentences(sentences, p_func):\n",
    "    corpus = []\n",
    "    for s in sentences:\n",
    "        corpus.append(p_func(s))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the word embedding model based on the current corpus\n",
    "corpus = parseSentences(sentences, parseSentenceBasic)\n",
    "word2Vec = Word2Vec(corpus, size=256, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordEmbedding(word, word2Vec):\n",
    "    try:\n",
    "        return torch.from_numpy(word2Vec.wv[word])\n",
    "    except KeyError:\n",
    "        return torch.from_numpy(word2Vec.wv[\"<UNK>\"])\n",
    "    \n",
    "def getWordEmbedding2(word, word2Vec):\n",
    "    try:\n",
    "        return word2Vec.wv[word]\n",
    "    except KeyError:\n",
    "        return word2Vec.wv[\"<UNK>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Network\n",
    "TODO: Figure out what you actually need to do lol<br>\n",
    "So far, I have the network outlined, but we need to figure out how to train the data<br>\n",
    "We also need to figure out how to define a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(256, 100)\n",
    "        self.hidden2 = nn.Linear(100, 150)\n",
    "        self.output = nn.Linear(150, 2)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X.to(device)\n",
    "        \n",
    "        q1 = self.hidden1(X)\n",
    "        h1 = F.relu(q1)\n",
    "        q2 = self.hidden2(h1)\n",
    "        h2 = F.relu(q2)\n",
    "        \n",
    "        return self.output(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShallowNetwork(\n",
       "  (hidden1): Linear(in_features=256, out_features=100, bias=True)\n",
       "  (hidden2): Linear(in_features=100, out_features=150, bias=True)\n",
       "  (output): Linear(in_features=150, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the corpus into a list of vectors for input\n",
    "def reviewToVecNaive(s):\n",
    "    result = torch.zeros(len(s),256)\n",
    "    for i in range(len(s)):\n",
    "        result[i] = getWordEmbedding(s[i], word2Vec)\n",
    "    return torch.sum(result, 0)\n",
    "\n",
    "def reviewToVecNaive2(s):\n",
    "    result = torch.zeros(256)\n",
    "    for i in range(len(s)):\n",
    "        result = result.add(getWordEmbedding(s[i], word2Vec))\n",
    "    return result\n",
    "\n",
    "def reviewToVecNaive3(s):\n",
    "    result = np.zeros((len(s), 256), dtype=np.float32)\n",
    "    for i in range(len(s)):\n",
    "        result[i] = getWordEmbedding(s[i], word2Vec)\n",
    "    return torch.from_numpy(np.sum(result, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(corpus)\n",
    "corpusVecs1 = [reviewToVecNaive3(s) for s in corpus[:N]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIdx = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "shallow_net = ShallowNetwork()\n",
    "shallow_net.cuda()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "def printOptInfo(optimizer):\n",
    "    print(optimizer.__class__.__name__, optimizer.param_groups[0]['lr'])\n",
    "\n",
    "def trainShallowNet(optimizer, epochs, corpusVecs, printResults=True):\n",
    "    if printResults:\n",
    "        printOptInfo(optimizer)\n",
    "    for epoch in range(epochs): \n",
    "        train_loss = []\n",
    "        shallow_net.train()\n",
    "        total_loss = total_correct = 0\n",
    "        total = trainIdx\n",
    "\n",
    "        for i in range(trainIdx):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            corpusVecs[i] = corpusVecs[i].to(device)\n",
    "\n",
    "            output = shallow_net(corpusVecs[i])\n",
    "            output = torch.unsqueeze(output, 0)\n",
    "            output = output.to(device)\n",
    "\n",
    "            _, x = output.data.topk(1)\n",
    "            target = torch.tensor([int(sentences[i][2])])\n",
    "            target = target.to(device)\n",
    "\n",
    "            if x[0][0] == target:\n",
    "                total_correct += 1\n",
    "\n",
    "            loss = loss_function(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "        if printResults:\n",
    "            print(\"epoch: {}, loss: {}, accuracy: {}\".format(epoch, np.mean(train_loss), total_correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printOptInfo(optimizer):\n",
    "    print(optimizer.__class__.__name__, optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 0.001\n",
      "epoch: 0, loss: 0.6765921560894698, accuracy: 0.5942\n",
      "epoch: 1, loss: 0.6789048265516758, accuracy: 0.57205\n",
      "SGD 0.001\n",
      "epoch: 0, loss: 0.6757887674849481, accuracy: 0.58495\n",
      "epoch: 1, loss: 0.6723869769826532, accuracy: 0.592\n",
      "epoch: 2, loss: 0.6770411373376847, accuracy: 0.5788\n",
      "epoch: 3, loss: 0.677973353369534, accuracy: 0.57975\n",
      "epoch: 4, loss: 0.6783318033911288, accuracy: 0.5763\n",
      "epoch: 5, loss: 0.680336127974838, accuracy: 0.57725\n",
      "epoch: 6, loss: 0.679368626422435, accuracy: 0.58505\n",
      "epoch: 7, loss: 0.6716068382002414, accuracy: 0.6017\n"
     ]
    }
   ],
   "source": [
    "# Testing results for SDG optimizer with constant lr, diff epochs\n",
    "shallow_net = ShallowNetwork().cuda()\n",
    "o1 = optim.SGD(shallow_net.parameters(), lr=0.001)\n",
    "trainShallowNet(o1, 2, corpusVecs1)\n",
    "\n",
    "shallow_net = ShallowNetwork().cuda()\n",
    "o2 = optim.SGD(shallow_net.parameters(), lr=0.001)\n",
    "trainShallowNet(o2, 8, corpusVecs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 0.0001\n",
      "epoch: 0, loss: 0.697416302045621, accuracy: 0.60095\n",
      "epoch: 1, loss: 0.6538178123567253, accuracy: 0.62615\n",
      "SGD 0.01\n",
      "epoch: 0, loss: nan, accuracy: 0.0195\n",
      "epoch: 1, loss: nan, accuracy: 0.0\n",
      "SGD 0.1\n",
      "epoch: 0, loss: nan, accuracy: 0.00335\n",
      "epoch: 1, loss: nan, accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Testing results for SDG optimizer with constant epochs, diff lr\n",
    "shallow_net = ShallowNetwork().cuda()\n",
    "o3 = optim.SGD(shallow_net.parameters(), lr=0.0001)\n",
    "trainShallowNet(o3, 2, corpusVecs1)\n",
    "\n",
    "shallow_net = ShallowNetwork().cuda()\n",
    "o4 = optim.SGD(shallow_net.parameters(), lr=0.01)\n",
    "trainShallowNet(o4, 2, corpusVecs1)\n",
    "\n",
    "shallow_net = ShallowNetwork().cuda()\n",
    "o5 = optim.SGD(shallow_net.parameters(), lr=0.1)\n",
    "trainShallowNet(o5, 2, corpusVecs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 0.0001\n",
      "epoch: 0, loss: 0.7003838335053064, accuracy: 0.5994\n",
      "epoch: 1, loss: 0.6560078274384141, accuracy: 0.62375\n",
      "epoch: 2, loss: 0.6496948119603098, accuracy: 0.6324\n",
      "epoch: 3, loss: 0.6455893912747502, accuracy: 0.6383\n",
      "epoch: 4, loss: 0.6431354025945067, accuracy: 0.6404\n",
      "epoch: 5, loss: 0.6400601583058014, accuracy: 0.64185\n",
      "epoch: 6, loss: 0.6372200701104477, accuracy: 0.64595\n",
      "epoch: 7, loss: 0.6354311815664172, accuracy: 0.6462\n",
      "epoch: 8, loss: 0.633373790150322, accuracy: 0.64905\n",
      "epoch: 9, loss: 0.6313983280704357, accuracy: 0.6485\n"
     ]
    }
   ],
   "source": [
    "shallow_net = ShallowNetwork().cuda()\n",
    "o_best_sgd = optim.SGD(shallow_net.parameters(), lr=0.0001)\n",
    "trainShallowNet(o_best_sgd, 10, corpusVecs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam 0.1\n",
      "epoch: 0, loss: 606.7561558526859, accuracy: 0.49975\n",
      "epoch: 1, loss: 4.72142732155174, accuracy: 0.4976\n",
      "Adam 0.01\n",
      "epoch: 0, loss: 3.656859737342596, accuracy: 0.499\n",
      "epoch: 1, loss: 0.7507467496782542, accuracy: 0.4952\n"
     ]
    }
   ],
   "source": [
    "# Testing results with Adam with 2 epochs\n",
    "shallow_net = ShallowNetwork().cuda()\n",
    "o6 = optim.Adam(shallow_net.parameters(), lr=0.1, betas=(0.9, 0.99)) # Starting with the best results found in the paper\n",
    "trainShallowNet(o6, 2, corpusVecs1)\n",
    "\n",
    "shallow_net = ShallowNetwork().cuda()\n",
    "o7 = optim.Adam(shallow_net.parameters(), lr=0.01) # Starting with the best results found in the paper\n",
    "trainShallowNet(o7, 2, corpusVecs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam 0.1\n",
      "epoch: 0, loss: 325.3814041033566, accuracy: 0.4988\n",
      "epoch: 1, loss: 0.7207487521916628, accuracy: 0.49715\n",
      "epoch: 2, loss: 0.7207487520843744, accuracy: 0.49715\n",
      "epoch: 3, loss: 0.7207487520709633, accuracy: 0.49715\n",
      "epoch: 4, loss: 0.7207487522661686, accuracy: 0.49715\n",
      "epoch: 5, loss: 0.7207487523317337, accuracy: 0.49715\n",
      "epoch: 6, loss: 0.7207487522795797, accuracy: 0.49715\n",
      "epoch: 7, loss: 0.7207487520948053, accuracy: 0.49715\n"
     ]
    }
   ],
   "source": [
    "# Testing results with Adam with more epochs using best parameters from before\n",
    "shallow_net = ShallowNetwork().cuda()\n",
    "o_best_adam = optim.Adam(shallow_net.parameters(), lr=0.1, betas=(0.9, 0.99)) # Starting with the best results found in the paper\n",
    "trainShallowNet(o_best_adam, 8, corpusVecs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After playing around with the training set, apply results to large test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "testIdx = len(corpusVecs1)\n",
    "\n",
    "def testShallowNet(corpusVecs, printResults=True):\n",
    "    shallow_net.eval()\n",
    "    if printResults:\n",
    "        print(\"Testing Validation set\")\n",
    "        \n",
    "    valid_loss = []\n",
    "    vtc = 0\n",
    "    total = testIdx - trainIdx\n",
    "\n",
    "    for i in range(trainIdx, testIdx):\n",
    "        corpusVecs[i] = corpusVecs[i].to(device)\n",
    "\n",
    "        output = shallow_net(corpusVecs1[i])\n",
    "        output = torch.unsqueeze(output,0)\n",
    "        output = output.to(device)\n",
    "\n",
    "        _, x = output.data.topk(1)\n",
    "        target = torch.tensor([int(sentences[i][2])])\n",
    "        target = target.to(device)\n",
    "\n",
    "        if x[0][0] == target:\n",
    "            vtc += 1\n",
    "\n",
    "        loss = loss_function(output, target)\n",
    "        valid_loss.append(loss.item())\n",
    "\n",
    "    if printResults:\n",
    "        print (\"Valid Loss: \", np.mean(valid_loss), \" Valid Accuracy: \", vtc/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Run this overnight b/c it's a lot of epochs lmao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 0.0001\n",
      "epoch: 0, loss: 0.7029884145474061, accuracy: 0.59845\n",
      "epoch: 1, loss: 0.6546152041204274, accuracy: 0.6256\n",
      "epoch: 2, loss: 0.6473501835002564, accuracy: 0.63295\n",
      "epoch: 3, loss: 0.6460502143951133, accuracy: 0.63695\n",
      "epoch: 4, loss: 0.6417039959196933, accuracy: 0.64185\n",
      "epoch: 5, loss: 0.6399227172822691, accuracy: 0.64245\n",
      "epoch: 6, loss: 0.637738271092996, accuracy: 0.6452\n",
      "epoch: 7, loss: 0.6356239701982588, accuracy: 0.648\n",
      "epoch: 8, loss: 0.6344645050564781, accuracy: 0.6472\n",
      "epoch: 9, loss: 0.6316201680244878, accuracy: 0.65185\n",
      "epoch: 10, loss: 0.631434486806579, accuracy: 0.64915\n",
      "epoch: 11, loss: 0.6294749275523238, accuracy: 0.6513\n",
      "epoch: 12, loss: 0.6292330946765841, accuracy: 0.65115\n",
      "epoch: 13, loss: 0.6256487735946663, accuracy: 0.6526\n",
      "epoch: 14, loss: 0.6239506203782744, accuracy: 0.6581\n",
      "epoch: 15, loss: 0.6237775511654093, accuracy: 0.6561\n",
      "epoch: 16, loss: 0.6213585338531993, accuracy: 0.6591\n",
      "epoch: 17, loss: 0.6192147739214823, accuracy: 0.6623\n",
      "epoch: 18, loss: 0.617934393032547, accuracy: 0.66375\n",
      "epoch: 19, loss: 0.6170392226247117, accuracy: 0.66435\n",
      "epoch: 20, loss: 0.6144488557382487, accuracy: 0.6648\n",
      "epoch: 21, loss: 0.612094573187083, accuracy: 0.66655\n",
      "epoch: 22, loss: 0.6095786985323765, accuracy: 0.67005\n",
      "epoch: 23, loss: 0.6076080000435934, accuracy: 0.6705\n",
      "epoch: 24, loss: 0.6048280370013789, accuracy: 0.6704\n",
      "epoch: 25, loss: 0.605272518467065, accuracy: 0.6744\n",
      "epoch: 26, loss: 0.6048733298436738, accuracy: 0.676\n",
      "epoch: 27, loss: 0.6004787615219132, accuracy: 0.6768\n",
      "epoch: 28, loss: 0.6014452463154681, accuracy: 0.6772\n",
      "epoch: 29, loss: 0.5973693903092295, accuracy: 0.6798\n",
      "epoch: 30, loss: 0.5932821591911838, accuracy: 0.67985\n",
      "epoch: 31, loss: 0.5926776339153759, accuracy: 0.68605\n",
      "epoch: 32, loss: 0.590983157900907, accuracy: 0.6829\n",
      "epoch: 33, loss: 0.5869806392277591, accuracy: 0.68475\n",
      "epoch: 34, loss: 0.5867356033431366, accuracy: 0.68725\n",
      "epoch: 35, loss: 0.5819412692687475, accuracy: 0.69065\n",
      "epoch: 36, loss: 0.5854994833840989, accuracy: 0.6904\n",
      "epoch: 37, loss: 0.5784349254908971, accuracy: 0.6942\n",
      "epoch: 38, loss: 0.5771182661625557, accuracy: 0.69285\n",
      "epoch: 39, loss: 0.5714435328695457, accuracy: 0.70175\n",
      "epoch: 40, loss: 0.5710779296646826, accuracy: 0.6993\n",
      "epoch: 41, loss: 0.5700725951203611, accuracy: 0.70225\n",
      "epoch: 42, loss: 0.5686850583199412, accuracy: 0.7013\n",
      "epoch: 43, loss: 0.5627937489484437, accuracy: 0.70575\n",
      "epoch: 44, loss: 0.5597033702788875, accuracy: 0.7088\n",
      "epoch: 45, loss: 0.5603066939040087, accuracy: 0.707\n",
      "epoch: 46, loss: 0.5541577864777996, accuracy: 0.7125\n",
      "epoch: 47, loss: 0.5533160711154341, accuracy: 0.71245\n",
      "epoch: 48, loss: 0.5512444839998148, accuracy: 0.7153\n",
      "epoch: 49, loss: 0.5449201235178858, accuracy: 0.71935\n",
      "Testing Validation set\n",
      "SGD 0.001\n",
      "Valid Loss:  0.7273511570460816  Valid Accuracy:  0.61252\n"
     ]
    }
   ],
   "source": [
    "shallow_net = ShallowNetwork().cuda()\n",
    "o_best_sgd = optim.SGD(shallow_net.parameters(), lr=0.0001)\n",
    "trainShallowNet(o_best_sgd, 50, corpusVecs1)\n",
    "testShallowNet(corpusVecs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Punctuation ###\n",
    "import string\n",
    "def parseSentenceRemovePunc(sentence):\n",
    "    sent = sentence[1]\n",
    "    sent = sent.translate(str.maketrans('', '', string.punctuation))\n",
    "    sent = sent.strip().split()\n",
    "    return [x.lower() for x in sent]\n",
    "\n",
    "def reviewToVecRemovePunc(s):\n",
    "    result = np.zeros((len(s), 256), dtype=np.float32)\n",
    "    for i in range(len(s)):\n",
    "        result[i] = getWordEmbedding(s[i], word2VecRP)\n",
    "    return torch.from_numpy(np.sum(result, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['im', 'so', 'pumped', 'for', 'the', 'runn', 'lol', 'yeet', 'hi', 'there']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parseSentenceRemovePunc((1,\"I'm so pumped!!! for the runn* lol yeet., hi, there\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusRP = parseSentences(sentences, parseSentenceRemovePunc)\n",
    "word2VecRP = Word2Vec(corpusRP, size=256, min_count=1)\n",
    "corpusVecsRP = [reviewToVecRemovePunc(s) for s in corpusRP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 0.0001\n",
      "epoch: 0, loss: 0.6904180389977992, accuracy: 0.60665\n",
      "epoch: 1, loss: 0.6519244625438004, accuracy: 0.6303\n",
      "epoch: 2, loss: 0.6461100714338943, accuracy: 0.63745\n",
      "epoch: 3, loss: 0.6429648605552735, accuracy: 0.6404\n",
      "epoch: 4, loss: 0.6395431984181515, accuracy: 0.6441\n",
      "epoch: 5, loss: 0.6372030795700848, accuracy: 0.64735\n",
      "epoch: 6, loss: 0.6342780151852989, accuracy: 0.64745\n",
      "epoch: 7, loss: 0.6318999478915707, accuracy: 0.6513\n",
      "epoch: 8, loss: 0.6307564444663003, accuracy: 0.6503\n",
      "epoch: 9, loss: 0.6280690464532003, accuracy: 0.65265\n"
     ]
    }
   ],
   "source": [
    "# Initial exploration of Removing Punctuation\n",
    "shallow_net = ShallowNetwork().cuda()\n",
    "o = optim.SGD(shallow_net.parameters(), lr=0.0001)\n",
    "trainShallowNet(o, 10, corpusVecsRP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Run overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.6832736623609439, accuracy: 0.61335\n",
      "epoch: 1, loss: 0.6423848252095282, accuracy: 0.63495\n",
      "epoch: 2, loss: 0.6355594107333571, accuracy: 0.6428\n",
      "epoch: 3, loss: 0.6304630756832659, accuracy: 0.6475\n",
      "epoch: 4, loss: 0.6258434915305116, accuracy: 0.6512\n",
      "epoch: 5, loss: 0.6209469932716339, accuracy: 0.6549\n",
      "epoch: 6, loss: 0.6169257361199707, accuracy: 0.65915\n",
      "epoch: 7, loss: 0.6140793929651379, accuracy: 0.65965\n",
      "epoch: 8, loss: 0.6096197547988966, accuracy: 0.6651\n",
      "epoch: 9, loss: 0.6069094866424799, accuracy: 0.66645\n",
      "epoch: 10, loss: 0.602978558184579, accuracy: 0.6693\n",
      "epoch: 11, loss: 0.5994665628220885, accuracy: 0.67195\n",
      "epoch: 12, loss: 0.5957826994009316, accuracy: 0.67455\n",
      "epoch: 13, loss: 0.5939640895336866, accuracy: 0.67545\n",
      "epoch: 14, loss: 0.5888997744682245, accuracy: 0.68005\n",
      "epoch: 15, loss: 0.5852831742266194, accuracy: 0.68205\n",
      "epoch: 16, loss: 0.5824117169490084, accuracy: 0.6848\n",
      "epoch: 17, loss: 0.5789790781266987, accuracy: 0.68625\n",
      "epoch: 18, loss: 0.5756213249120862, accuracy: 0.6889\n",
      "epoch: 19, loss: 0.572312447472848, accuracy: 0.6939\n",
      "epoch: 20, loss: 0.5691483730711043, accuracy: 0.6956\n",
      "epoch: 21, loss: 0.5652675110611133, accuracy: 0.69645\n",
      "epoch: 26, loss: 0.5463513389771805, accuracy: 0.7129\n",
      "epoch: 27, loss: 0.5438426966940985, accuracy: 0.7139\n",
      "epoch: 28, loss: 0.5373425148034469, accuracy: 0.7207\n",
      "epoch: 29, loss: 0.5354732269635424, accuracy: 0.72215\n",
      "epoch: 30, loss: 0.5329062099918723, accuracy: 0.7223\n",
      "epoch: 31, loss: 0.5289112232098356, accuracy: 0.72475\n",
      "epoch: 32, loss: 0.5236868246499449, accuracy: 0.7282\n",
      "epoch: 33, loss: 0.5209366796993651, accuracy: 0.73105\n",
      "epoch: 34, loss: 0.5180496536514722, accuracy: 0.7314\n",
      "epoch: 35, loss: 0.5119811043098569, accuracy: 0.73215\n",
      "epoch: 36, loss: 0.5126102585011162, accuracy: 0.7338\n",
      "epoch: 37, loss: 0.5100563179470599, accuracy: 0.7368\n",
      "epoch: 38, loss: 0.5031303722616285, accuracy: 0.7424\n",
      "epoch: 39, loss: 0.49882358335983007, accuracy: 0.7441\n",
      "epoch: 40, loss: 0.4972663764514029, accuracy: 0.7464\n",
      "epoch: 41, loss: 0.49028200445994735, accuracy: 0.75245\n",
      "epoch: 42, loss: 0.4919952813620679, accuracy: 0.7484\n",
      "epoch: 43, loss: 0.48474467829316853, accuracy: 0.75515\n",
      "epoch: 48, loss: 0.4673842358656228, accuracy: 0.76365\n",
      "epoch: 49, loss: 0.4655091358747333, accuracy: 0.7655\n",
      "Testing Validation set\n",
      "SGD 0.001\n",
      "Valid Loss:  1.1567847950702348  Valid Accuracy:  0.58495\n"
     ]
    }
   ],
   "source": [
    "# Testing model wtih 50 epochs\n",
    "o = optim.SGD(shallow_net.parameters(), lr=0.0001)\n",
    "trainShallowNet(o, 50, corpusVecsRP)\n",
    "testShallowNet(corpusVecsRP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make punctuation an embedding ###\n",
    "def parseSentencePuncEmbed(sentence):\n",
    "    sent = sentence[1]\n",
    "    punc = ['.', '!', ';', '?', '-']\n",
    "    for p in punc:  \n",
    "        sent = sent.replace(p, \" \" + p + \" \")\n",
    "    sent = sent.replace(\"'\", \"\")\n",
    "    sent = sent.strip().split()\n",
    "    return [x.lower() for x in sent]\n",
    "\n",
    "def reviewToVecPuncEmbed(s):\n",
    "    result = np.zeros((len(s), 256), dtype=np.float32)\n",
    "    for i in range(len(s)):\n",
    "        result[i] = getWordEmbedding(s[i], word2VecPE)\n",
    "    return torch.from_numpy(np.sum(result, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusPE = parseSentences(sentences, parseSentencePuncEmbed)\n",
    "word2VecPE = Word2Vec(corpusPE, size=256, min_count=1)\n",
    "corpusVecsPE = [reviewToVecPuncEmbed(s) for s in corpusPE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 0.0001\n",
      "epoch: 0, loss: 0.69196751480503, accuracy: 0.6056\n",
      "epoch: 1, loss: 0.6530303657909855, accuracy: 0.6277\n",
      "epoch: 2, loss: 0.648223162284866, accuracy: 0.631\n",
      "epoch: 3, loss: 0.6443316187039018, accuracy: 0.63725\n",
      "epoch: 4, loss: 0.6412390139104799, accuracy: 0.6419\n",
      "epoch: 5, loss: 0.6398565146304667, accuracy: 0.64215\n",
      "epoch: 6, loss: 0.6372144710576162, accuracy: 0.64715\n",
      "epoch: 7, loss: 0.6358025217071176, accuracy: 0.64815\n",
      "epoch: 8, loss: 0.6339809098771307, accuracy: 0.64985\n",
      "epoch: 9, loss: 0.6329009722508258, accuracy: 0.6497\n"
     ]
    }
   ],
   "source": [
    "# TODO Perform the training\n",
    "shallow_net = ShallowNetwork().cuda()\n",
    "o = optim.SGD(shallow_net.parameters(), lr=0.0001)\n",
    "trainShallowNet(o, 10, corpusVecsPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Run overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 0.0001\n",
      "epoch: 0, loss: 0.6889368819605326, accuracy: 0.6038\n",
      "epoch: 1, loss: 0.652522301142104, accuracy: 0.6279\n",
      "epoch: 2, loss: 0.6455427042042836, accuracy: 0.6367\n",
      "epoch: 3, loss: 0.6412872657289729, accuracy: 0.64255\n",
      "epoch: 4, loss: 0.6383467690318823, accuracy: 0.6432\n",
      "epoch: 5, loss: 0.6365085242732428, accuracy: 0.6458\n",
      "epoch: 6, loss: 0.6344501096766442, accuracy: 0.64835\n",
      "epoch: 7, loss: 0.6320376964886673, accuracy: 0.6479\n",
      "epoch: 8, loss: 0.629931101786159, accuracy: 0.6513\n",
      "epoch: 9, loss: 0.6289591054193675, accuracy: 0.6521\n",
      "epoch: 10, loss: 0.6264607416269835, accuracy: 0.65455\n",
      "epoch: 11, loss: 0.6252018424151465, accuracy: 0.65695\n",
      "epoch: 12, loss: 0.6241470107048052, accuracy: 0.65575\n",
      "epoch: 13, loss: 0.6229727788352407, accuracy: 0.6592\n",
      "epoch: 14, loss: 0.6204118521956727, accuracy: 0.6614\n",
      "epoch: 15, loss: 0.619339306929987, accuracy: 0.6624\n",
      "epoch: 16, loss: 0.6165382479340303, accuracy: 0.66215\n",
      "epoch: 17, loss: 0.615444421865046, accuracy: 0.6645\n",
      "epoch: 18, loss: 0.613253317237366, accuracy: 0.66515\n",
      "epoch: 19, loss: 0.6120908678259235, accuracy: 0.6649\n",
      "epoch: 20, loss: 0.6091868127758615, accuracy: 0.66775\n",
      "epoch: 21, loss: 0.6074232896894216, accuracy: 0.67145\n",
      "epoch: 22, loss: 0.6065352447224315, accuracy: 0.67015\n",
      "epoch: 27, loss: 0.5989340867064661, accuracy: 0.6773\n",
      "epoch: 28, loss: 0.5961456846619025, accuracy: 0.6793\n",
      "epoch: 29, loss: 0.5918844935586676, accuracy: 0.6809\n",
      "epoch: 30, loss: 0.5915692231770605, accuracy: 0.68395\n",
      "epoch: 31, loss: 0.588175299747847, accuracy: 0.6853\n",
      "epoch: 32, loss: 0.586658936794661, accuracy: 0.68745\n",
      "epoch: 33, loss: 0.5828374606826343, accuracy: 0.6889\n",
      "epoch: 34, loss: 0.5800995952734258, accuracy: 0.6949\n",
      "epoch: 40, loss: 0.5640683947809972, accuracy: 0.70315\n",
      "epoch: 41, loss: 0.5631178702547215, accuracy: 0.7072\n",
      "epoch: 42, loss: 0.5594090521004051, accuracy: 0.70675\n",
      "epoch: 43, loss: 0.5549721560269129, accuracy: 0.71225\n",
      "epoch: 44, loss: 0.5511736266743857, accuracy: 0.71505\n",
      "epoch: 45, loss: 0.5516842401686125, accuracy: 0.713\n",
      "epoch: 46, loss: 0.5543152150396723, accuracy: 0.7133\n",
      "epoch: 47, loss: 0.5484864161052275, accuracy: 0.71405\n",
      "epoch: 48, loss: 0.5444687689783982, accuracy: 0.7171\n",
      "epoch: 49, loss: 0.5438815009823302, accuracy: 0.71735\n",
      "Testing Validation set\n",
      "SGD 0.001\n",
      "Valid Loss:  2.9384893030405324  Valid Accuracy:  0.53912\n"
     ]
    }
   ],
   "source": [
    "shallow_net = ShallowNetwork().cuda()\n",
    "o = optim.SGD(shallow_net.parameters(), lr=0.0001)\n",
    "trainShallowNet(o, 50, corpusVecsPE)\n",
    "testShallowNet(corpusVecsPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making tf-idf corpus dict\n",
    "from collections import defaultdict\n",
    "tfidf_dict = defaultdict(int)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    for word in parseSentencePuncEmbed(sentences[i]):\n",
    "        tfidf_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TF-IDF Parsing ###\n",
    "import math\n",
    "N = len(sentences)\n",
    "def reviewToVecTFIDF(s):\n",
    "    result = np.zeros((len(s), 256), dtype=np.float32)\n",
    "\n",
    "    doc_counts = defaultdict(int)\n",
    "    for word in s:\n",
    "        doc_counts[word] += 1\n",
    "    \n",
    "    for i in range(len(s)):\n",
    "        weight = torch.tensor(doc_counts[s[i]] * math.log(N/tfidf_dict[s[i]]))\n",
    "        word_embedding = getWordEmbedding(s[i], word2VecPE)\n",
    "        result[i] = word_embedding*weight.expand_as(word_embedding)\n",
    "        \n",
    "    return torch.from_numpy(np.sum(result, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusVecsTFIDF = [reviewToVecTFIDF(s) for s in corpusPE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 0.0001\n",
      "epoch: 0, loss: 1.3747586511999368, accuracy: 0.54925\n",
      "epoch: 1, loss: 1.2956613364724443, accuracy: 0.53415\n",
      "epoch: 2, loss: 21.70679119032817, accuracy: 0.5371\n",
      "epoch: 3, loss: 5992.674446704036, accuracy: 0.5161\n",
      "epoch: 4, loss: 0.9042090472906827, accuracy: 0.49825\n",
      "epoch: 5, loss: 0.7160526506245136, accuracy: 0.49975\n",
      "epoch: 6, loss: 0.6929773669540882, accuracy: 0.5011\n",
      "epoch: 7, loss: 0.6929947181999684, accuracy: 0.5026\n",
      "epoch: 8, loss: 0.6929855198308825, accuracy: 0.50265\n",
      "epoch: 9, loss: 0.6929498706966638, accuracy: 0.50265\n"
     ]
    }
   ],
   "source": [
    "# TODO Perform the training\n",
    "shallow_net = ShallowNetwork().cuda()\n",
    "o = optim.SGD(shallow_net.parameters(), lr=0.0001)\n",
    "trainShallowNet(o, 10, corpusVecsTFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Run Overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 0.0001\n",
      "epoch: 0, loss: 1.5166704046139494, accuracy: 0.5327\n",
      "epoch: 1, loss: 1.5156483787558972, accuracy: 0.5381\n",
      "epoch: 2, loss: 1.3860277008742095, accuracy: 0.54615\n",
      "epoch: 3, loss: 0.6912884895667434, accuracy: 0.53885\n",
      "epoch: 4, loss: 0.6869653450384736, accuracy: 0.5336\n",
      "epoch: 5, loss: 0.6829224729686976, accuracy: 0.5572\n",
      "epoch: 6, loss: 0.6818263136737048, accuracy: 0.569\n",
      "epoch: 7, loss: 0.6803631385959685, accuracy: 0.56845\n",
      "epoch: 8, loss: 0.6787210705757141, accuracy: 0.5814\n",
      "epoch: 9, loss: 0.6782761797986925, accuracy: 0.58095\n",
      "epoch: 10, loss: 0.6777408777654171, accuracy: 0.57755\n",
      "epoch: 11, loss: 0.6774849384561181, accuracy: 0.5803\n",
      "epoch: 12, loss: 0.6763261337310076, accuracy: 0.58055\n",
      "epoch: 17, loss: 0.6744417943183333, accuracy: 0.5817\n",
      "epoch: 18, loss: 0.6731176926750689, accuracy: 0.5843\n",
      "epoch: 19, loss: 0.6730973766155541, accuracy: 0.58605\n",
      "epoch: 20, loss: 0.6727174837231636, accuracy: 0.58805\n",
      "epoch: 21, loss: 0.6717091576907783, accuracy: 0.58765\n",
      "epoch: 22, loss: 0.6712359697233885, accuracy: 0.5892\n",
      "epoch: 23, loss: 0.6700448490843177, accuracy: 0.5922\n",
      "epoch: 24, loss: 0.6692433661768213, accuracy: 0.59085\n",
      "epoch: 25, loss: 0.6711841009167955, accuracy: 0.58445\n",
      "epoch: 26, loss: 0.6686667427297681, accuracy: 0.5907\n",
      "epoch: 27, loss: 0.6674333994559943, accuracy: 0.594\n",
      "epoch: 28, loss: 0.6662549842827022, accuracy: 0.5952\n",
      "epoch: 29, loss: 0.6663992689084262, accuracy: 0.595\n",
      "epoch: 30, loss: 0.6660977005915716, accuracy: 0.59315\n",
      "epoch: 31, loss: 0.6649673402121291, accuracy: 0.59485\n",
      "epoch: 32, loss: 0.6639727226885036, accuracy: 0.59965\n",
      "epoch: 33, loss: 0.6632283971980214, accuracy: 0.5984\n",
      "epoch: 34, loss: 0.6620687608323992, accuracy: 0.599\n",
      "epoch: 35, loss: 0.6616901416772977, accuracy: 0.5955\n",
      "epoch: 36, loss: 0.6599656500674318, accuracy: 0.6032\n",
      "epoch: 37, loss: 0.6595750283815898, accuracy: 0.60215\n",
      "epoch: 38, loss: 0.6590215509587899, accuracy: 0.60225\n",
      "epoch: 39, loss: 0.6582147360270842, accuracy: 0.6055\n",
      "epoch: 40, loss: 0.6597799037156626, accuracy: 0.59815\n",
      "epoch: 41, loss: 0.6584858009973541, accuracy: 0.6021\n",
      "epoch: 42, loss: 0.6572727681767138, accuracy: 0.60205\n",
      "epoch: 43, loss: 0.6566029967650305, accuracy: 0.6025\n",
      "epoch: 44, loss: 0.7563229080835357, accuracy: 0.56875\n",
      "epoch: 45, loss: 0.7068455959250219, accuracy: 0.50895\n",
      "epoch: 46, loss: 0.6983436939151958, accuracy: 0.51295\n",
      "epoch: 47, loss: 0.6957808765035123, accuracy: 0.50765\n",
      "epoch: 48, loss: 0.7265208785139025, accuracy: 0.50495\n",
      "epoch: 49, loss: 0.6978195454373955, accuracy: 0.49915\n",
      "Testing Validation set\n",
      "SGD 0.001\n",
      "Valid Loss:  261.37019645810193  Valid Accuracy:  0.49182\n"
     ]
    }
   ],
   "source": [
    "shallow_net = ShallowNetwork().cuda()\n",
    "o = optim.SGD(shallow_net.parameters(), lr=0.0001)\n",
    "trainShallowNet(o, 50, corpusVecsTFIDF)\n",
    "testShallowNet(corpusVecsTFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
